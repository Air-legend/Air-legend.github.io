---
title: Multi Game Decision Transformers
author: bean
date: 2022-07-26 15:50:00 +0800
categories: [Deep Learning, RL]
tags: [DeepMind]
---
# 简介
 研究人员提出了一种[DeepNash](https://sites.google.com/view/multi-game-transformers)通用结构，能够有效的执行多种任务和快速的学习决策新任务。
 
 模型利用基于 transformer 的模型在 offline 情况下训练出在46个 atari 游戏中接近人类玩家水平的智能体。同时，该模型在视觉和语言任务中的某些方面，包括模型尺寸对表现的影响（文章使用 power-law 来说明）和通过 fine-tuning 在新任务上的快速适应能力上有着类似的趋势。老样子，经过各种实验比对，证实该模型拥有最棒的表现和扩展性，

# 强化学习序列模型
文章将离线强化学习过程看作是一个序列模型问题，以历史token $x_{<i}$ 作为条件来建模 $x_i$ 的概率分布 $P_\theta(x_i|x_{<i})$, 其中序列使用了以下定义形式:
> $x = <...,o_1^t, ..., o_M^t, \hat{R}^t, a^t, r^t, ...>$

其中 $t$ 是当前时间步，$M$ 表示将每个 obs 图像观测切分的数量。
![image patch](../common/deepnash/img_patch.jpg)


<style>p{text-indent:1em}</style>